{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Pass\n",
    "- take care of nulls\n",
    "- data errors\n",
    "- data types\n",
    "- dummy vars\n",
    "- split\n",
    "- scaling\n",
    "- features (select kbest, recursive feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"student/student-mat.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  G1          395 non-null    int64 \n",
      " 31  G2          395 non-null    int64 \n",
      " 32  G3          395 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 102.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "      <td>10.908861</td>\n",
       "      <td>10.713924</td>\n",
       "      <td>10.415190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "      <td>3.319195</td>\n",
       "      <td>3.761505</td>\n",
       "      <td>4.581443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  395.000000  395.000000  395.000000  395.000000  \n",
       "mean     5.708861   10.908861   10.713924   10.415190  \n",
       "std      8.003096    3.319195    3.761505    4.581443  \n",
       "min      0.000000    3.000000    0.000000    0.000000  \n",
       "25%      0.000000    8.000000    9.000000    8.000000  \n",
       "50%      4.000000   11.000000   11.000000   11.000000  \n",
       "75%      8.000000   13.000000   13.000000   14.000000  \n",
       "max     75.000000   19.000000   19.000000   20.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Object Columns**\n",
    "\n",
    "How many unique values in each column? We need to answer this so that we know if creating dummy variables makes sense (or if it ends up creating way too many columns).\n",
    "- Create a boolean mask of the columns indicating whether the datatype is object or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes == 'object' returns a series. \n",
    "# convert this to an array\n",
    "mask = np.array(df.dtypes == \"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter the dataframe columns by using the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using iloc, the df will filter out all the index locations \n",
    "# (columns number) where mast is false \n",
    "\n",
    "obj_df = df.iloc[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loop through all the object columns and generate value counts of each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP    349\n",
      "MS     46\n",
      "Name: school, dtype: int64\n",
      "\n",
      "\n",
      "F    208\n",
      "M    187\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "\n",
      "U    307\n",
      "R     88\n",
      "Name: address, dtype: int64\n",
      "\n",
      "\n",
      "GT3    281\n",
      "LE3    114\n",
      "Name: famsize, dtype: int64\n",
      "\n",
      "\n",
      "T    354\n",
      "A     41\n",
      "Name: Pstatus, dtype: int64\n",
      "\n",
      "\n",
      "other       141\n",
      "services    103\n",
      "at_home      59\n",
      "teacher      58\n",
      "health       34\n",
      "Name: Mjob, dtype: int64\n",
      "\n",
      "\n",
      "other       217\n",
      "services    111\n",
      "teacher      29\n",
      "at_home      20\n",
      "health       18\n",
      "Name: Fjob, dtype: int64\n",
      "\n",
      "\n",
      "course        145\n",
      "home          109\n",
      "reputation    105\n",
      "other          36\n",
      "Name: reason, dtype: int64\n",
      "\n",
      "\n",
      "mother    273\n",
      "father     90\n",
      "other      32\n",
      "Name: guardian, dtype: int64\n",
      "\n",
      "\n",
      "no     344\n",
      "yes     51\n",
      "Name: schoolsup, dtype: int64\n",
      "\n",
      "\n",
      "yes    242\n",
      "no     153\n",
      "Name: famsup, dtype: int64\n",
      "\n",
      "\n",
      "no     214\n",
      "yes    181\n",
      "Name: paid, dtype: int64\n",
      "\n",
      "\n",
      "yes    201\n",
      "no     194\n",
      "Name: activities, dtype: int64\n",
      "\n",
      "\n",
      "yes    314\n",
      "no      81\n",
      "Name: nursery, dtype: int64\n",
      "\n",
      "\n",
      "yes    375\n",
      "no      20\n",
      "Name: higher, dtype: int64\n",
      "\n",
      "\n",
      "yes    329\n",
      "no      66\n",
      "Name: internet, dtype: int64\n",
      "\n",
      "\n",
      "no     263\n",
      "yes    132\n",
      "Name: romantic, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through each column name in the list of columns\n",
    "# print the value_counts \n",
    "\n",
    "for col in obj_df.columns:\n",
    "    print(obj_df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school         2\n",
       "sex            2\n",
       "age            8\n",
       "address        2\n",
       "famsize        2\n",
       "Pstatus        2\n",
       "Medu           5\n",
       "Fedu           5\n",
       "Mjob           5\n",
       "Fjob           5\n",
       "reason         4\n",
       "guardian       3\n",
       "traveltime     4\n",
       "studytime      4\n",
       "failures       4\n",
       "schoolsup      2\n",
       "famsup         2\n",
       "paid           2\n",
       "activities     2\n",
       "nursery        2\n",
       "higher         2\n",
       "internet       2\n",
       "romantic       2\n",
       "famrel         5\n",
       "freetime       5\n",
       "goout          5\n",
       "Dalc           5\n",
       "Walc           5\n",
       "health         5\n",
       "absences      34\n",
       "G1            17\n",
       "G2            17\n",
       "G3            18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with new dummy vars\n",
    "dummy_df = pd.get_dummies(obj_df, dummy_na=False, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframe with dummies to our original dataframe\n",
    "# via column (axis=1)\n",
    "df = pd.concat([df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop object columns from df\n",
    "df.drop(columns=obj_df.columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_validate, test = train_test_split(df,\n",
    "                                        test_size=.2,\n",
    "                                        random_state=123)\n",
    "train, validate = train_test_split(train_validate, \n",
    "                                   test_size=.3,\n",
    "                                   random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into X and y dataframes**\n",
    "- y = G3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x df's are all cols except G3\n",
    "X_train = train.drop(columns=['G3'])\n",
    "X_validate = validate.drop(columns=['G3'])\n",
    "X_test = test.drop(columns=['G3'])\n",
    "\n",
    "# y df's are just G3\n",
    "y_train = train[['G3']]\n",
    "y_validate = validate[['G3']]\n",
    "y_test = test[['G3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(copy=True)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframes out of the scaled arrays that were generated by the scaler tranform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, \n",
    "             columns = X_train.columns.values).\\\n",
    "             set_index(X_train.index.values)\n",
    "\n",
    "X_validate_scaled = pd.DataFrame(X_validate_scaled, \n",
    "             columns = X_validate.columns.values).\\\n",
    "             set_index(X_validate.index.values)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, \n",
    "             columns = X_test.columns.values).\\\n",
    "             set_index(X_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection\n",
    "1. SelectKBest\n",
    "2. RFE: Recursive Feature Elimination\n",
    "\n",
    "##### SelectKBest\n",
    "- filter method\n",
    "- find and keep the attributes with the highest correlation to the target variable.\n",
    "\n",
    "How?\n",
    "1. the correlation between each attribute & the target is computed.\n",
    "2. converted to an F-score and then p-value.\n",
    "3. top k attributes are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the f_selector object, defining the scoring method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(f_regression, k = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the object to our X and y data(train). This will score, rank and ID the top k feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = f_selector.fit(X_train_scaled, y_train.G3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform our dataset to reduct to the K Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 41)\n",
      "(221, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train_reduced = f_selector.transform(X_train_scaled)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_support = f_selector.get_support()\n",
    "type(f_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with just the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using iloc, the df will filter out all the index locations \n",
    "# (columns number) where mask is false\n",
    "# the : before the comma is for rows (so if we wanted to filter rows \n",
    "# we could say like 10:20), and after the comma is for columns. \n",
    "\n",
    "X_reduced_scaled = X_train_scaled.iloc[:,f_support]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataframe is ready for modeling!\n",
    "\n",
    "X_reduced_scaled.head()\n",
    "\n",
    "View the features selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'sex_M',\n",
       " 'Mjob_other',\n",
       " 'reason_reputation',\n",
       " 'guardian_other',\n",
       " 'higher_yes']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_feature = X_train_scaled.iloc[:, f_support].columns.tolist()\n",
    "f_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could run through again with a different k value and select those best features. We can then run the different dataframes through models and select the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Feature Engineering: RFE**\n",
    "\n",
    "wrapper method\n",
    "\n",
    "Recursively build model after model with fewer and fewer features. It will then identify which model performs the best. Then, return which features were used in that model. Those are the features we will keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the RFE object, setting the hyperparameters to be our linear model above(lm) and the number of features we want returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lm, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = rfe.fit_transform(X_train_scaled, y_train.G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_scaled_rfe = X_train_scaled.iloc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'traveltime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'Mjob_health',\n",
       " 'Mjob_other',\n",
       " 'Mjob_services',\n",
       " 'schoolsup_yes',\n",
       " 'famsup_yes',\n",
       " 'internet_yes']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features selected using rfe\n",
    "X_reduced_scaled_rfe.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'sex_M',\n",
       " 'Mjob_other',\n",
       " 'reason_reputation',\n",
       " 'guardian_other',\n",
       " 'higher_yes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features selected using selectkbest\n",
    "X_reduced_scaled.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
